# projeto_pipelineETL
Pipeline ETL automatizado
O projeto foi desenvolvido em Python na versão 3.11.11 utilizando PySpark na versão 3.5.0, garantindo eficiência no processamento e manipulação de grandes volumes de dados de forma distribuída. 

Para o desenvolvimento dos scripts, foi utilizado o Framework Test Driven Development (TDD):

O plano segue as seguintes etapas:

Extração → Coleta dos dados abertos de todas as empresas brasileiras a partir da Receita Federal.

Tratamento e Consolidação → Limpeza, padronização e unificação das informações extraídas.

Categorização → Classificação das empresas com base em categorias sugeridas pela Trust Works.

Geração do DataFrame Final → Construção da estrutura final dos dados para análises e tomada de decisão.

