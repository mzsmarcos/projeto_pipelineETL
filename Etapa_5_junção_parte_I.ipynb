{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mzsmarcos/projeto_pipelineETL/blob/main/Etapa_5_jun%C3%A7%C3%A3o_parte_I.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Jun√ß√£o Parte 1**\n",
        "\n",
        "Nesse notebook est√£o os c√≥digos da primeira parte de jun√ß√£o dos arquivos do site da Receita Federal:\n",
        "\n",
        "Sequ√™ncia das jun√ß√µes: Ordenada por criticidade\n",
        "\n",
        "1 - df_empresas_brasil_1 = df_estab + df_socios\n",
        "\n",
        "2 - df_empresas_brasil_1 + df_empresas\n",
        "\n",
        "3 - df_empresas_brasil_1 + df_simples\n",
        "\n"
      ],
      "metadata": {
        "id": "dZVMZpoUfgyz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nigaxeaJkMCh"
      },
      "source": [
        "Configura√ß√£o do PySpark -  instalar o PySpark no Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WB8LpMTWkLSp",
        "outputId": "d7b1ad22-f2bd-4e14-b870-235a2acda0ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "# Instalar o PySpark\n",
        "!pip install pyspark\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3h6QW5hCk3Oe"
      },
      "source": [
        "Executar a instala√ß√£o do PySpark e configurar o ambiente Spark.\n",
        "\n",
        "Isso √© feito definindo algumas vari√°veis de ambiente para garantir que o Spark funcione corretamente no Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "p9L1Vi5qkrn1",
        "outputId": "1603ee0e-36e1-4d8a-dfb5-4e3899e68366"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java libatk-wrapper-java-jni libfontenc1\n",
            "  libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin libgtk2.0-common libice-dev librsvg2-common\n",
            "  libsm-dev libxkbfile1 libxt-dev libxtst6 libxxf86dga1 openjdk-8-jdk-headless openjdk-8-jre\n",
            "  openjdk-8-jre-headless x11-utils\n",
            "Suggested packages:\n",
            "  gvfs libice-doc libsm-doc libxt-doc openjdk-8-demo openjdk-8-source visualvm libnss-mdns\n",
            "  fonts-nanum fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei fonts-wqy-zenhei\n",
            "  fonts-indic mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java libatk-wrapper-java-jni libfontenc1\n",
            "  libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin libgtk2.0-common libice-dev librsvg2-common\n",
            "  libsm-dev libxkbfile1 libxt-dev libxtst6 libxxf86dga1 openjdk-8-jdk openjdk-8-jdk-headless\n",
            "  openjdk-8-jre openjdk-8-jre-headless x11-utils\n",
            "0 upgraded, 22 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 50.1 MB of archives.\n",
            "After this operation, 169 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java all 0.38.0-5build1 [53.1 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java-jni amd64 0.38.0-5build1 [49.0 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-common all 2.24.33-2ubuntu2.1 [125 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-0 amd64 2.24.33-2ubuntu2.1 [2,038 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail18 amd64 2.24.33-2ubuntu2.1 [15.9 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail-common amd64 2.24.33-2ubuntu2.1 [132 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-bin amd64 2.24.33-2ubuntu2.1 [7,936 B]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libice-dev amd64 2:1.0.10-1build2 [51.4 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 librsvg2-common amd64 2.52.5+dfsg-3ubuntu0.2 [17.7 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsm-dev amd64 2:1.2.3-1build2 [18.1 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jre-headless amd64 8u442-b06~us1-0ubuntu1~22.04 [30.8 MB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jre amd64 8u442-b06~us1-0ubuntu1~22.04 [75.3 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jdk-headless amd64 8u442-b06~us1-0ubuntu1~22.04 [8,864 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jdk amd64 8u442-b06~us1-0ubuntu1~22.04 [4,077 kB]\n",
            "Fetched 50.1 MB in 2s (26.8 MB/s)\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "(Reading database ... 125044 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-dejavu-core_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-2build1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../01-fonts-dejavu-extra_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-2build1) ...\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../02-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../03-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../04-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "Preparing to unpack .../05-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../06-x11-utils_7.7+5build2_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+5build2) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../07-libatk-wrapper-java_0.38.0-5build1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../08-libatk-wrapper-java-jni_0.38.0-5build1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "Preparing to unpack .../09-libgtk2.0-common_2.24.33-2ubuntu2.1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../10-libgtk2.0-0_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../11-libgail18_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../12-libgail-common_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../13-libgtk2.0-bin_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libice-dev:amd64.\n",
            "Preparing to unpack .../14-libice-dev_2%3a1.0.10-1build2_amd64.deb ...\n",
            "Unpacking libice-dev:amd64 (2:1.0.10-1build2) ...\n",
            "Selecting previously unselected package librsvg2-common:amd64.\n",
            "Preparing to unpack .../15-librsvg2-common_2.52.5+dfsg-3ubuntu0.2_amd64.deb ...\n",
            "Unpacking librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Selecting previously unselected package libsm-dev:amd64.\n",
            "Preparing to unpack .../16-libsm-dev_2%3a1.2.3-1build2_amd64.deb ...\n",
            "Unpacking libsm-dev:amd64 (2:1.2.3-1build2) ...\n",
            "Selecting previously unselected package libxt-dev:amd64.\n",
            "Preparing to unpack .../17-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n",
            "Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../18-openjdk-8-jre-headless_8u442-b06~us1-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u442-b06~us1-0ubuntu1~22.04) ...\n",
            "Selecting previously unselected package openjdk-8-jre:amd64.\n",
            "Preparing to unpack .../19-openjdk-8-jre_8u442-b06~us1-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre:amd64 (8u442-b06~us1-0ubuntu1~22.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../20-openjdk-8-jdk-headless_8u442-b06~us1-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u442-b06~us1-0ubuntu1~22.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk:amd64.\n",
            "Preparing to unpack .../21-openjdk-8-jdk_8u442-b06~us1-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk:amd64 (8u442-b06~us1-0ubuntu1~22.04) ...\n",
            "Setting up libice-dev:amd64 (2:1.0.10-1build2) ...\n",
            "Setting up libsm-dev:amd64 (2:1.2.3-1build2) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u442-b06~us1-0ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up fonts-dejavu-core (2.37-2build1) ...\n",
            "Setting up librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Setting up fonts-dejavu-extra (2.37-2build1) ...\n",
            "Setting up libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u442-b06~us1-0ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "Setting up libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Setting up x11-utils (7.7+5build2) ...\n",
            "Setting up libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Setting up libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Setting up openjdk-8-jre:amd64 (8u442-b06~us1-0ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/policytool to provide /usr/bin/policytool (policytool) in auto mode\n",
            "Setting up openjdk-8-jdk:amd64 (8u442-b06~us1-0ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/appletviewer to provide /usr/bin/appletviewer (appletviewer) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libgdk-pixbuf-2.0-0:amd64 (2.42.8+dfsg-1ubuntu0.3) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Instalar Java 8\n",
        "!apt-get install openjdk-8-jdk -y\n",
        "\n",
        "# Baixar o Apache Spark\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n",
        "\n",
        "# Extrair o Apache Spark\n",
        "!tar xf spark-3.5.0-bin-hadoop3.tgz\n",
        "\n",
        "# Definir vari√°veis de ambiente\n",
        "import os # M√≥dulo para interagir com o sistema operacional, como manipula√ß√£o de arquivos e diret√≥rios\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\"\n",
        "\n",
        "# Instalar as bibliotecas PySpark e Findspark\n",
        "!pip install -q pyspark==3.5.0 findspark\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6I03-onnFfZ",
        "outputId": "78a21011-12ac-4b0b-e7c2-db9c402cc82e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 382M\n",
            "drwxr-xr-x  1 root root 4.0K Mar 13 13:31 sample_data\n",
            "drwxr-xr-x 13 1000 1000 4.0K Sep  9  2023 spark-3.5.0-bin-hadoop3\n",
            "-rw-r--r--  1 root root 382M Sep  9  2023 spark-3.5.0-bin-hadoop3.tgz\n"
          ]
        }
      ],
      "source": [
        "# Verificar se o arquivo foi baixado\n",
        "!ls -lh\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwyHmqlJ7y7o"
      },
      "source": [
        "Criar a Sess√£o Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wKpgQX9-uVY",
        "outputId": "397ec499-ddff-4eb4-cc63-474e49ea4aab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vers√£o do Spark: 3.5.0\n"
          ]
        }
      ],
      "source": [
        "# Importar as bibliotecas\n",
        "import findspark # Permite localizar e configurar o Spark no ambiente, garantindo que o PySpark possa ser usado\n",
        "findspark.init(\"/content/spark-3.5.0-bin-hadoop3\")\n",
        "\n",
        "from pyspark.sql import SparkSession  # Importa a classe SparkSession para criar uma sess√£o do Spark e interagir com DataFrames\n",
        "\n",
        "# Criar a sess√£o Spark\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"PySparkExample\") \\\n",
        "    .config(\"spark.driver.memory\", \"4g\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Verificar se a sess√£o foi criada corretamente\n",
        "print(\"Vers√£o do Spark:\", spark.version)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmt3_Tn6OnG7"
      },
      "outputs": [],
      "source": [
        "# Os\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9trpJPzwPO-4",
        "outputId": "a79e8436-38f0-48b2-ec0b-77e62fea65be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Montando o Google Drive no Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aud8cnn5b9Lw",
        "outputId": "b6f1a9d5-ebd6-48d6-9a96-2b9dec018707"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cnae.parquet\n",
            "estab_unificado.parquet\n",
            "empresas_unificado.parquet\n",
            "motivos.parquet\n",
            "municipios.parquet\n",
            "natureza.parquet\n",
            "paises.parquet\n",
            "qualificacao.parquet\n",
            "simples.parquet\n",
            "socios_unificado.parquet\n",
            "socios_agrupado.parquet\n"
          ]
        }
      ],
      "source": [
        "# Identifica√ß√£o dos arquivos parquet no diret√≥rio\n",
        "\n",
        "#Lista arquivos do diret√≥rio\n",
        "\n",
        "files = os.listdir(\"/content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet\")\n",
        "\n",
        "# Exibe os arquivos\n",
        "for file in files:\n",
        "    print(file)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnwAvRfb2x_y",
        "outputId": "94b9b658-02f6-40e8-854a-afd101fc92cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Verificando cnpj_basico em dataframe com 60959932 linhas...\n",
            "  ‚Üí Valores √∫nicos: 60959931\n",
            "  ‚ö†Ô∏è H√° 1 duplicatas na chave 'cnpj_basico'!\n",
            "\n",
            "üîç Verificando cnpj_basico em dataframe com 64017368 linhas...\n",
            "  ‚Üí Valores √∫nicos: 60959931\n",
            "  ‚ö†Ô∏è H√° 3057437 duplicatas na chave 'cnpj_basico'!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Valida√ß√£o das chaves de jun√ß√£o\n",
        "\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "def verificar_duplicatas(df, chave):\n",
        "    total_linhas = df.count()\n",
        "    valores_unicos = df.select(chave).distinct().count()\n",
        "\n",
        "    print(f\"üîç Verificando {chave} em dataframe com {total_linhas} linhas...\")\n",
        "    print(f\"  ‚Üí Valores √∫nicos: {valores_unicos}\")\n",
        "\n",
        "    if valores_unicos < total_linhas:\n",
        "        print(f\"  ‚ö†Ô∏è H√° {total_linhas - valores_unicos} duplicatas na chave '{chave}'!\\n\")\n",
        "    else:\n",
        "        print(f\"  ‚úÖ Nenhuma duplicata encontrada na chave '{chave}'!\\n\")\n",
        "\n",
        "# Rodar para cada dataframe e chave\n",
        "verificar_duplicatas(empresas_unificado, \"cnpj_basico\")\n",
        "verificar_duplicatas(estab_unificado, \"cnpj_basico\")\n",
        "verificar_duplicatas(simples, \"cnpj_basico\")\n",
        "\n",
        "# Para df_socios, precisamos verificar m√∫ltiplas chaves\n",
        "for chave in [\"cnpj_basico\", \"array_nome_socio_pf_pj\", \"array_cpf_cnpj_socio\", \"array_cpf_representante_legal\", \"array_nome_representante\"]:\n",
        "    verificar_duplicatas(socios_agrupado, chave)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Jun√ßao dos arquivos\n",
        "\n",
        "from pyspark.sql.functions import lit\n",
        "from pyspark.sql.utils import AnalysisException\n",
        "import os\n",
        "import traceback\n",
        "\n",
        "# Caminho do diret√≥rio no Google Drive\n",
        "drive_directory = \"/content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet\"\n",
        "\n",
        "# Lista de arquivos parquet\n",
        "arquivos_parquet = [\n",
        "    \"estab_unificado.parquet\",\n",
        "    \"empresas_unificado.parquet\",\n",
        "    \"simples.parquet\",\n",
        "    \"qualificacao.parquet\",\n",
        "    \"natureza.parquet\",\n",
        "    \"municipios.parquet\",\n",
        "    \"motivos.parquet\",\n",
        "    \"paises.parquet\",\n",
        "    \"cnae.parquet\",\n",
        "    \"socios_agrupado.parquet\"\n",
        "]\n",
        "\n",
        "# Configura√ß√µes otimizadas para PySpark\n",
        "spark.conf.set(\"spark.sql.parquet.compression.codec\", \"snappy\")\n",
        "spark.conf.set(\"spark.sql.parquet.mergeSchema\", \"false\")\n",
        "spark.conf.set(\"spark.sql.parquet.filterPushdown\", \"true\")\n",
        "spark.conf.set(\"spark.sql.files.maxPartitionBytes\", \"128m\")\n",
        "spark.conf.set(\"spark.sql.shuffle.partitions\", \"200\")\n",
        "\n",
        "# Fun√ß√£o para verificar se o arquivo parquet √© v√°lido\n",
        "def verificar_arquivo_parquet(caminho):\n",
        "    \"\"\"Verifica se um arquivo parquet pode ser lido corretamente.\"\"\"\n",
        "    try:\n",
        "        # Tenta ler apenas o esquema do arquivo, sem carregar dados\n",
        "        schema = spark.read.option(\"mergeSchema\", \"false\").parquet(caminho).schema\n",
        "        print(f\"Esquema do arquivo validado: {caminho}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao verificar esquema do arquivo {caminho}: {e}\")\n",
        "        return False\n",
        "\n",
        "# Dicion√°rio para armazenar os dataframes\n",
        "dataframes = {}\n",
        "\n",
        "total_linhas = 0  # Vari√°vel para armazenar o total de linhas\n",
        "\n",
        "# Loop para ler os arquivos parquet com tratamento de erros melhorado\n",
        "for arquivo in arquivos_parquet:\n",
        "    caminho_completo = f\"{drive_directory}/{arquivo}\"\n",
        "    df_name = arquivo.split(\".\")[0]\n",
        "\n",
        "    if os.path.exists(caminho_completo):\n",
        "        print(f\"Verificando arquivo: {caminho_completo}\")\n",
        "\n",
        "        # Verifica se o arquivo √© v√°lido antes de tentar carreg√°-lo\n",
        "        if verificar_arquivo_parquet(caminho_completo):\n",
        "            try:\n",
        "                # Tenta ler o arquivo sem contar as linhas inicialmente\n",
        "                print(f\"Carregando arquivo: {caminho_completo}\")\n",
        "                df = spark.read.option(\"mergeSchema\", \"false\").parquet(caminho_completo)\n",
        "\n",
        "                # Verifica se o DataFrame pode ser processado\n",
        "                try:\n",
        "                    # Tenta executar uma opera√ß√£o simples no DataFrame\n",
        "                    df.dtypes  # Isso n√£o executa um job Spark, apenas recupera metadados\n",
        "                    print(f\"Arquivo {arquivo} carregado com sucesso.\")\n",
        "\n",
        "                    # S√≥ cache se o DataFrame for usado nos joins\n",
        "                    if df_name == \"estab_unificado\" or df_name in [\"socios_agrupado\", \"empresas_unificado\", \"simples\"]:\n",
        "                        df = df.cache()\n",
        "                        print(f\"DataFrame {df_name} colocado em cache.\")\n",
        "\n",
        "                    # Contagem de linhas com tratamento de erros\n",
        "                    try:\n",
        "                        print(f\"Contando linhas para {df_name}...\")\n",
        "                        num_linhas = df.count()\n",
        "                        total_linhas += num_linhas\n",
        "                        print(f\"Arquivo {arquivo} tem {num_linhas} linhas.\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"Erro ao contar linhas do arquivo {arquivo}: {e}\")\n",
        "                        print(f\"Detalhes do erro: {traceback.format_exc()}\")\n",
        "                        # Continua sem contar as linhas\n",
        "                        num_linhas = 0\n",
        "\n",
        "                    dataframes[df_name] = df\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Erro ao processar o DataFrame {df_name}: {e}\")\n",
        "                    print(f\"Detalhes do erro: {traceback.format_exc()}\")\n",
        "                    dataframes[df_name] = None\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Erro ao ler o arquivo {arquivo}: {e}\")\n",
        "                print(f\"Detalhes do erro: {traceback.format_exc()}\")\n",
        "                dataframes[df_name] = None\n",
        "        else:\n",
        "            print(f\"Arquivo {arquivo} n√£o p√¥de ser validado.\")\n",
        "            dataframes[df_name] = None\n",
        "    else:\n",
        "        print(f\"Arquivo n√£o encontrado: {caminho_completo}\")\n",
        "        dataframes[df_name] = None\n",
        "\n",
        "print(f\"Total estimado de linhas nos arquivos carregados: {total_linhas}\")\n",
        "\n",
        "# Verifica se o DataFrame principal foi carregado\n",
        "df_empresas_brasil_1 = dataframes.get(\"estab_unificado\")\n",
        "\n",
        "if df_empresas_brasil_1 is not None:\n",
        "    print(\"DataFrame estab_unificado carregado com sucesso. Prosseguindo com os joins.\")\n",
        "\n",
        "    # Lista de dataframes a serem unidos\n",
        "    dataframes_a_unir = [\"socios_agrupado\", \"empresas_unificado\", \"simples\"]\n",
        "    total_joins = len(dataframes_a_unir)\n",
        "\n",
        "    for i, df_name in enumerate(dataframes_a_unir):\n",
        "        df_atual = dataframes.get(df_name)\n",
        "        if df_atual is not None:\n",
        "            try:\n",
        "                # Verifica se a coluna de join existe\n",
        "                colunas_df_atual = df_atual.columns\n",
        "                if \"cnpj_basico\" in colunas_df_atual:\n",
        "                    try:\n",
        "                        # Executa o join com tratamento de erros\n",
        "                        print(f\"Iniciando join com {df_name}...\")\n",
        "                        df_empresas_brasil_1 = df_empresas_brasil_1.join(df_atual, [\"cnpj_basico\"], \"left\")\n",
        "\n",
        "                        progresso = ((i + 1) / total_joins) * 100\n",
        "                        print(f\"Join com {df_name} conclu√≠do. Progresso: {progresso:.2f}%\")\n",
        "\n",
        "                        # Libera mem√≥ria do DataFrame que j√° foi usado no join\n",
        "                        try:\n",
        "                            df_atual.unpersist()\n",
        "                            print(f\"Mem√≥ria liberada para o DataFrame {df_name}\")\n",
        "                        except:\n",
        "                            print(f\"N√£o foi poss√≠vel liberar a mem√≥ria para {df_name}\")\n",
        "\n",
        "                        dataframes[df_name] = None\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"Erro ao realizar join com {df_name}: {e}\")\n",
        "                        print(f\"Detalhes do erro: {traceback.format_exc()}\")\n",
        "                else:\n",
        "                    print(f\"DataFrame {df_name} n√£o cont√©m a coluna 'cnpj_basico'. Join ignorado.\")\n",
        "                    print(f\"Colunas dispon√≠veis: {colunas_df_atual}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Erro ao processar o DataFrame {df_name} para join: {e}\")\n",
        "                print(f\"Detalhes do erro: {traceback.format_exc()}\")\n",
        "        else:\n",
        "            print(f\"DataFrame {df_name} n√£o encontrado, join ignorado.\")\n",
        "\n",
        "    try:\n",
        "        # Usa um m√©todo seguro para tratar dados faltantes\n",
        "        print(\"Tratando valores nulos...\")\n",
        "        df_empresas_brasil_1 = df_empresas_brasil_1.na.fill(\"N√£o aplicado\")\n",
        "        print(\"Tratamento de valores nulos conclu√≠do.\")\n",
        "\n",
        "        # Caminho de sa√≠da\n",
        "        output_path = f\"{drive_directory}/df_empresas_brasil_1\"\n",
        "\n",
        "        # Determina o n√∫mero de parti√ß√µes\n",
        "        num_colunas = len(df_empresas_brasil_1.columns)\n",
        "        linhas_estimadas = df_empresas_brasil_1.count()  # Conta as linhas reais\n",
        "\n",
        "        # Ajusta o n√∫mero de parti√ß√µes com base no tamanho estimado\n",
        "        tamanho_estimado = linhas_estimadas * num_colunas * 8  # Estimativa grosseira em bytes\n",
        "        tamanho_parti√ß√£o = 128 * 1024 * 1024  # 128MB por parti√ß√£o\n",
        "        partition_count = max(1, min(int(tamanho_estimado / tamanho_parti√ß√£o), 200))\n",
        "\n",
        "        print(f\"Iniciando salvamento com {partition_count} parti√ß√µes...\")\n",
        "\n",
        "        # Tenta salvar o resultado com tratamento de erros\n",
        "        try:\n",
        "            df_empresas_brasil_1.repartition(partition_count) \\\n",
        "                .write \\\n",
        "                .mode(\"overwrite\") \\\n",
        "                .option(\"compression\", \"snappy\") \\\n",
        "                .option(\"parquet.block.size\", \"134217728\") \\\n",
        "                .option(\"parquet.page.size\", \"1048576\") \\\n",
        "                .option(\"parquet.enable.dictionary\", \"true\") \\\n",
        "                .parquet(output_path)\n",
        "\n",
        "            print(f\"Salvamento conclu√≠do com {partition_count} parti√ß√µes.\")\n",
        "            print(f\"Arquivos salvos com compress√£o Snappy em: {output_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao salvar o resultado: {e}\")\n",
        "            print(f\"Detalhes do erro: {traceback.format_exc()}\")\n",
        "\n",
        "            # Tenta um salvamento mais simples\n",
        "            print(\"Tentando salvar com configura√ß√µes b√°sicas...\")\n",
        "            try:\n",
        "                df_empresas_brasil_1.write.mode(\"overwrite\").parquet(output_path)\n",
        "                print(\"Salvamento b√°sico conclu√≠do.\")\n",
        "            except Exception as e2:\n",
        "                print(f\"Tamb√©m falhou o salvamento b√°sico: {e2}\")\n",
        "                print(f\"Detalhes do erro: {traceback.format_exc()}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao processar o DataFrame final: {e}\")\n",
        "        print(f\"Detalhes do erro: {traceback.format_exc()}\")\n",
        "\n",
        "    # Libera mem√≥ria dos DataFrames lidos\n",
        "    for df_name, df in dataframes.items():\n",
        "        if df is not None:\n",
        "            try:\n",
        "                df.unpersist()\n",
        "                print(f\"Mem√≥ria liberada para o DataFrame {df_name}\")\n",
        "            except:\n",
        "                pass\n",
        "else:\n",
        "    print(\"DataFrame estab_unificado n√£o encontrado. Verifique a leitura dos arquivos.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17uRfbANsMdP",
        "outputId": "7af994dc-c367-40db-e1da-11ea59cd46ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verificando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/estab_unificado.parquet\n",
            "Esquema do arquivo validado: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/estab_unificado.parquet\n",
            "Carregando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/estab_unificado.parquet\n",
            "Arquivo estab_unificado.parquet carregado com sucesso.\n",
            "DataFrame estab_unificado colocado em cache.\n",
            "Contando linhas para estab_unificado...\n",
            "Arquivo estab_unificado.parquet tem 64017368 linhas.\n",
            "Verificando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/empresas_unificado.parquet\n",
            "Esquema do arquivo validado: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/empresas_unificado.parquet\n",
            "Carregando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/empresas_unificado.parquet\n",
            "Arquivo empresas_unificado.parquet carregado com sucesso.\n",
            "DataFrame empresas_unificado colocado em cache.\n",
            "Contando linhas para empresas_unificado...\n",
            "Arquivo empresas_unificado.parquet tem 60959932 linhas.\n",
            "Verificando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/simples.parquet\n",
            "Esquema do arquivo validado: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/simples.parquet\n",
            "Carregando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/simples.parquet\n",
            "Arquivo simples.parquet carregado com sucesso.\n",
            "DataFrame simples colocado em cache.\n",
            "Contando linhas para simples...\n",
            "Arquivo simples.parquet tem 41720964 linhas.\n",
            "Verificando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/qualificacao.parquet\n",
            "Esquema do arquivo validado: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/qualificacao.parquet\n",
            "Carregando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/qualificacao.parquet\n",
            "Arquivo qualificacao.parquet carregado com sucesso.\n",
            "Contando linhas para qualificacao...\n",
            "Arquivo qualificacao.parquet tem 68 linhas.\n",
            "Verificando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/natureza.parquet\n",
            "Esquema do arquivo validado: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/natureza.parquet\n",
            "Carregando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/natureza.parquet\n",
            "Arquivo natureza.parquet carregado com sucesso.\n",
            "Contando linhas para natureza...\n",
            "Arquivo natureza.parquet tem 90 linhas.\n",
            "Verificando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/municipios.parquet\n",
            "Esquema do arquivo validado: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/municipios.parquet\n",
            "Carregando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/municipios.parquet\n",
            "Arquivo municipios.parquet carregado com sucesso.\n",
            "Contando linhas para municipios...\n",
            "Arquivo municipios.parquet tem 5571 linhas.\n",
            "Verificando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/motivos.parquet\n",
            "Esquema do arquivo validado: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/motivos.parquet\n",
            "Carregando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/motivos.parquet\n",
            "Arquivo motivos.parquet carregado com sucesso.\n",
            "Contando linhas para motivos...\n",
            "Arquivo motivos.parquet tem 61 linhas.\n",
            "Verificando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/paises.parquet\n",
            "Esquema do arquivo validado: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/paises.parquet\n",
            "Carregando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/paises.parquet\n",
            "Arquivo paises.parquet carregado com sucesso.\n",
            "Contando linhas para paises...\n",
            "Arquivo paises.parquet tem 255 linhas.\n",
            "Verificando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/cnae.parquet\n",
            "Esquema do arquivo validado: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/cnae.parquet\n",
            "Carregando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/cnae.parquet\n",
            "Arquivo cnae.parquet carregado com sucesso.\n",
            "Contando linhas para cnae...\n",
            "Arquivo cnae.parquet tem 1359 linhas.\n",
            "Verificando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/socios_agrupado.parquet\n",
            "Esquema do arquivo validado: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/socios_agrupado.parquet\n",
            "Carregando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/socios_agrupado.parquet\n",
            "Arquivo socios_agrupado.parquet carregado com sucesso.\n",
            "DataFrame socios_agrupado colocado em cache.\n",
            "Contando linhas para socios_agrupado...\n",
            "Arquivo socios_agrupado.parquet tem 14443458 linhas.\n",
            "Total estimado de linhas nos arquivos carregados: 181149126\n",
            "DataFrame estab_unificado carregado com sucesso. Prosseguindo com os joins.\n",
            "Iniciando join com socios_agrupado...\n",
            "Join com socios_agrupado conclu√≠do. Progresso: 33.33%\n",
            "Mem√≥ria liberada para o DataFrame socios_agrupado\n",
            "Iniciando join com empresas_unificado...\n",
            "Join com empresas_unificado conclu√≠do. Progresso: 66.67%\n",
            "Mem√≥ria liberada para o DataFrame empresas_unificado\n",
            "Iniciando join com simples...\n",
            "Join com simples conclu√≠do. Progresso: 100.00%\n",
            "Mem√≥ria liberada para o DataFrame simples\n",
            "Tratando valores nulos...\n",
            "Tratamento de valores nulos conclu√≠do.\n",
            "Iniciando salvamento com 200 parti√ß√µes...\n",
            "Salvamento conclu√≠do com 200 parti√ß√µes.\n",
            "Arquivos salvos com compress√£o Snappy em: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/df_empresas_brasil_1\n",
            "Mem√≥ria liberada para o DataFrame estab_unificado\n",
            "Mem√≥ria liberada para o DataFrame qualificacao\n",
            "Mem√≥ria liberada para o DataFrame natureza\n",
            "Mem√≥ria liberada para o DataFrame municipios\n",
            "Mem√≥ria liberada para o DataFrame motivos\n",
            "Mem√≥ria liberada para o DataFrame paises\n",
            "Mem√≥ria liberada para o DataFrame cnae\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostra algumas linhas do DataFrame final para inspe√ß√£o\n",
        "df_empresas_brasil_1.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoJS4QAyFZob",
        "outputId": "b250d7e3-0935-4914-894b-295e1cd7e981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+-------+----------------+--------------------+-----------------+------------------+---------------------+---------------+------------+---------------------+---------------------+----------------------+--------------+--------------------+------+--------------------+-----------------+--------+---+---------+------------+------------+------------+------------+------------+------------+--------------------+-----------------+----------------------+------------------+----------------------+--------------------+---------------------+----------------------------+--------------------+-----------------------------+------------------------+-----------------------------+----------------------+----------------------+--------------------+----------------+----------------------------+--------------+-----------------+--------------------+-------------+------------------+-----------------+------------+--------------+-------------+\n",
            "|cnpj_basico|cnpj_ordem|cnpj_dv|id_matriz_filial|       nome_fantasia|cod_sit_cadastral|data_sit_cadastral|cod_mot_sit_cadastral|nome_cidade_ext|    cod_pais|data_inicio_atividade|cnae_fiscal_principal|cnae_fiscal_secundaria|tipo_de_lograd|          logradouro|numero|         complemento|           bairro|     cep| uf|municipio|       ddd_1|       tel_1|       ddd_2|       tel_2|     ddd_fax|     num_fax|  correio_eletronico|situacao_especial|data_situacao_especial|array_cod_id_socio|array_nome_socio_pf_pj|array_cpf_cnpj_socio|array_cod_quali_socio|array_data_entrada_sociedade|array_cod_pais_socio|array_cpf_representante_legal|array_nome_representante|array_cod_quali_representante|array_cod_faixa_etaria|array_nome_quali_socio|        razao_social|cod_nat_juridica|cod_qualificacao_responsavel|capital_social|cod_porte_empresa|ente_federativo_resp|opcao_simples|data_opcao_simples|data_excl_simples|   opcao_mei|data_opcao_mei|data_excl_mei|\n",
            "+-----------+----------+-------+----------------+--------------------+-----------------+------------------+---------------------+---------------+------------+---------------------+---------------------+----------------------+--------------+--------------------+------+--------------------+-----------------+--------+---+---------+------------+------------+------------+------------+------------+------------+--------------------+-----------------+----------------------+------------------+----------------------+--------------------+---------------------+----------------------------+--------------------+-----------------------------+------------------------+-----------------------------+----------------------+----------------------+--------------------+----------------+----------------------------+--------------+-----------------+--------------------+-------------+------------------+-----------------+------------+--------------+-------------+\n",
            "|   54140564|      0001|     59|               1|        N√£o aplicado|               08|          20240425|                   01|   N√£o aplicado|N√£o aplicado|             20240301|              4930202|       4930204,4930201|       AVENIDA|               ARAXA|   236|        N√£o aplicado|JARDIM VERDE VIDA|76888000| RO|     0685|          69|    93242103|N√£o aplicado|N√£o aplicado|N√£o aplicado|N√£o aplicado|SILVAPEREIRAALINE...|     N√£o aplicado|          N√£o aplicado|              NULL|                  NULL|                NULL|                 NULL|                        NULL|                NULL|                         NULL|                    NULL|                         NULL|                  NULL|                  NULL|54.140.564 ALINE ...|            2135|                          50|      10000,00|               01|        N√£o aplicado|            N|          20240301|         20240425|           N|      20240301|     20240425|\n",
            "|   13587990|      0001|     58|               1|        N√£o aplicado|               02|          20110503|                   00|   N√£o aplicado|N√£o aplicado|             20110503|              4772500|       4781400,9602501|       AVENIDA|DOUTOR JOSE THOMA...|    57|        N√£o aplicado|       FAROLANDIA|49030270| SE|     3105|          79|    98320369|N√£o aplicado|N√£o aplicado|N√£o aplicado|N√£o aplicado|FALECONOSCO.JOSYC...|     N√£o aplicado|          N√£o aplicado|              NULL|                  NULL|                NULL|                 NULL|                        NULL|                NULL|                         NULL|                    NULL|                         NULL|                  NULL|                  NULL|13.587.990 JOSENI...|            2135|                          50|      30000,00|               01|        N√£o aplicado|            N|          20110503|         20241231|           N|      20110503|     20241231|\n",
            "|   53782995|      0001|     56|               1|       MCR DO BRASIL|               02|          20240202|                   00|   N√£o aplicado|         105|             20240202|              6204000|  6311900,6319400,6...|       AVENIDA|            PAULISTA|  1106|SALA  01         ...|       BELA VISTA|01310914| SP|     7107|          41|    98880068|        0000|    00000000|N√£o aplicado|N√£o aplicado|ABERTURA@CONTABIL...|     N√£o aplicado|          N√£o aplicado|               [2]|  [MARCELO DA CONCE...|       [***042907**]|                 [49]|                  [20240202]|                  []|                [***000000**]|                      []|                         [00]|                   [5]|  [S√≥cio-Administra...|GLOBAL TECNOLOGIA...|            2062|                          49|      12000,00|               01|        N√£o aplicado|            S|          20240202|         00000000|           N|      00000000|     00000000|\n",
            "|   40310289|      0001|     60|               1|        N√£o aplicado|               02|          20190606|                   00|   N√£o aplicado|N√£o aplicado|             20190606|              6911701|          N√£o aplicado|           RUA|BELARMINO DE MEND...|   107|           SALA  102|           CENTRO|85851100| PR|     7563|          45|    30290465|N√£o aplicado|N√£o aplicado|N√£o aplicado|N√£o aplicado|        N√£o aplicado|     N√£o aplicado|          N√£o aplicado|            [2, 2]|  [SANDRA ALVES GOG...|[***948169**, ***...|             [49, 49]|        [20190606, 20190606]|                  []|         [***000000**, ***...|                      []|                     [00, 00]|                [4, 5]|  [S√≥cio-Administra...|BITTENCOURT & GOG...|            2232|                          49|       2000,00|               01|        N√£o aplicado|            S|          20240101|         00000000|           N|      00000000|     00000000|\n",
            "|   35005578|      0001|     15|               1|LANCHONETE ESCORPIAO|               08|          20000519|                   01|   N√£o aplicado|N√£o aplicado|             19891003|              4723700|          N√£o aplicado|       AVENIDA|   SARGENTO HERMINIO|  1755|        N√£o aplicado|      SAO VICENTE|63700001| CE|     1383|N√£o aplicado|N√£o aplicado|N√£o aplicado|N√£o aplicado|N√£o aplicado|N√£o aplicado|        N√£o aplicado|     N√£o aplicado|          N√£o aplicado|              NULL|                  NULL|                NULL|                 NULL|                        NULL|                NULL|                         NULL|                    NULL|                         NULL|                  NULL|                  NULL|MARIA DE PAULA PO...|            2135|                          50|          0,00|               05|        N√£o aplicado| N√£o aplicado|      N√£o aplicado|     N√£o aplicado|N√£o aplicado|  N√£o aplicado| N√£o aplicado|\n",
            "+-----------+----------+-------+----------------+--------------------+-----------------+------------------+---------------------+---------------+------------+---------------------+---------------------+----------------------+--------------+--------------------+------+--------------------+-----------------+--------+---+---------+------------+------------+------------+------------+------------+------------+--------------------+-----------------+----------------------+------------------+----------------------+--------------------+---------------------+----------------------------+--------------------+-----------------------------+------------------------+-----------------------------+----------------------+----------------------+--------------------+----------------+----------------------------+--------------+-----------------+--------------------+-------------+------------------+-----------------+------------+--------------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRaVo7XhH0U0QvDJr44otA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}