{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mzsmarcos/projeto_pipelineETL/blob/main/Etapa_7_jun%C3%A7%C3%A3o_%C3%BAnica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Etapa de jun√ß√£o**\n",
        "\n",
        "C√≥digo de jun√ß√£o de uma √∫nica vez.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dZVMZpoUfgyz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nigaxeaJkMCh"
      },
      "source": [
        "Configura√ß√£o do PySpark -  instalar o PySpark no Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WB8LpMTWkLSp",
        "outputId": "ba4af302-2944-476a-e83e-0eff8c1e7042"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "# Instalar o PySpark\n",
        "!pip install pyspark\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3h6QW5hCk3Oe"
      },
      "source": [
        "Executar a instala√ß√£o do PySpark e configurar o ambiente Spark.\n",
        "\n",
        "Isso √© feito definindo algumas vari√°veis de ambiente para garantir que o Spark funcione corretamente no Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "p9L1Vi5qkrn1",
        "outputId": "b73257f3-2863-48e7-b0b1-512cfa0b7a21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java libatk-wrapper-java-jni libfontenc1\n",
            "  libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin libgtk2.0-common librsvg2-common libxkbfile1\n",
            "  libxt-dev libxtst6 libxxf86dga1 openjdk-8-jdk-headless openjdk-8-jre openjdk-8-jre-headless\n",
            "  x11-utils\n",
            "Suggested packages:\n",
            "  gvfs libxt-doc openjdk-8-demo openjdk-8-source visualvm libnss-mdns fonts-nanum\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei fonts-wqy-zenhei fonts-indic\n",
            "  mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java libatk-wrapper-java-jni libfontenc1\n",
            "  libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin libgtk2.0-common librsvg2-common libxkbfile1\n",
            "  libxt-dev libxtst6 libxxf86dga1 openjdk-8-jdk openjdk-8-jdk-headless openjdk-8-jre\n",
            "  openjdk-8-jre-headless x11-utils\n",
            "0 upgraded, 20 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 50.1 MB of archives.\n",
            "After this operation, 169 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java all 0.38.0-5build1 [53.1 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java-jni amd64 0.38.0-5build1 [49.0 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-common all 2.24.33-2ubuntu2.1 [125 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-0 amd64 2.24.33-2ubuntu2.1 [2,038 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail18 amd64 2.24.33-2ubuntu2.1 [15.9 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail-common amd64 2.24.33-2ubuntu2.1 [132 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-bin amd64 2.24.33-2ubuntu2.1 [7,936 B]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 librsvg2-common amd64 2.52.5+dfsg-3ubuntu0.2 [17.7 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jre-headless amd64 8u442-b06~us1-0ubuntu1~22.04 [30.8 MB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jre amd64 8u442-b06~us1-0ubuntu1~22.04 [75.3 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jdk-headless amd64 8u442-b06~us1-0ubuntu1~22.04 [8,864 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jdk amd64 8u442-b06~us1-0ubuntu1~22.04 [4,077 kB]\n",
            "Fetched 50.1 MB in 2s (22.2 MB/s)\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "(Reading database ... 126209 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-dejavu-core_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-2build1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../01-fonts-dejavu-extra_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-2build1) ...\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../02-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../03-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../04-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "Preparing to unpack .../05-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../06-x11-utils_7.7+5build2_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+5build2) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../07-libatk-wrapper-java_0.38.0-5build1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../08-libatk-wrapper-java-jni_0.38.0-5build1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "Preparing to unpack .../09-libgtk2.0-common_2.24.33-2ubuntu2.1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../10-libgtk2.0-0_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../11-libgail18_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../12-libgail-common_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../13-libgtk2.0-bin_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package librsvg2-common:amd64.\n",
            "Preparing to unpack .../14-librsvg2-common_2.52.5+dfsg-3ubuntu0.2_amd64.deb ...\n",
            "Unpacking librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Selecting previously unselected package libxt-dev:amd64.\n",
            "Preparing to unpack .../15-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n",
            "Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../16-openjdk-8-jre-headless_8u442-b06~us1-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u442-b06~us1-0ubuntu1~22.04) ...\n",
            "Selecting previously unselected package openjdk-8-jre:amd64.\n",
            "Preparing to unpack .../17-openjdk-8-jre_8u442-b06~us1-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre:amd64 (8u442-b06~us1-0ubuntu1~22.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../18-openjdk-8-jdk-headless_8u442-b06~us1-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u442-b06~us1-0ubuntu1~22.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk:amd64.\n",
            "Preparing to unpack .../19-openjdk-8-jdk_8u442-b06~us1-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk:amd64 (8u442-b06~us1-0ubuntu1~22.04) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u442-b06~us1-0ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up fonts-dejavu-core (2.37-2build1) ...\n",
            "Setting up librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Setting up fonts-dejavu-extra (2.37-2build1) ...\n",
            "Setting up libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u442-b06~us1-0ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "Setting up libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Setting up x11-utils (7.7+5build2) ...\n",
            "Setting up libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Setting up libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Setting up openjdk-8-jre:amd64 (8u442-b06~us1-0ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/policytool to provide /usr/bin/policytool (policytool) in auto mode\n",
            "Setting up openjdk-8-jdk:amd64 (8u442-b06~us1-0ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/appletviewer to provide /usr/bin/appletviewer (appletviewer) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libgdk-pixbuf-2.0-0:amd64 (2.42.8+dfsg-1ubuntu0.3) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Instalar Java 8\n",
        "!apt-get install openjdk-8-jdk -y\n",
        "\n",
        "# Baixar o Apache Spark\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n",
        "\n",
        "# Extrair o Apache Spark\n",
        "!tar xf spark-3.5.0-bin-hadoop3.tgz\n",
        "\n",
        "# Definir vari√°veis de ambiente\n",
        "import os # M√≥dulo para interagir com o sistema operacional, como manipula√ß√£o de arquivos e diret√≥rios\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\"\n",
        "\n",
        "# Instalar as bibliotecas PySpark e Findspark\n",
        "!pip install -q pyspark==3.5.0 findspark\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6I03-onnFfZ",
        "outputId": "2f7d1f20-546e-46b3-ccc1-c86936bfc87b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 382M\n",
            "drwxr-xr-x  1 root root 4.0K Mar 19 13:34 sample_data\n",
            "drwxr-xr-x 13 1000 1000 4.0K Sep  9  2023 spark-3.5.0-bin-hadoop3\n",
            "-rw-r--r--  1 root root 382M Sep  9  2023 spark-3.5.0-bin-hadoop3.tgz\n"
          ]
        }
      ],
      "source": [
        "# Verificar se o arquivo foi baixado\n",
        "!ls -lh\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwyHmqlJ7y7o"
      },
      "source": [
        "Criar a Sess√£o Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wKpgQX9-uVY",
        "outputId": "c453dad1-c1ac-45e3-880f-c0e44e27218f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vers√£o do Spark: 3.5.0\n"
          ]
        }
      ],
      "source": [
        "# Importar as bibliotecas\n",
        "import findspark # Permite localizar e configurar o Spark no ambiente, garantindo que o PySpark possa ser usado\n",
        "findspark.init(\"/content/spark-3.5.0-bin-hadoop3\")\n",
        "\n",
        "from pyspark.sql import SparkSession  # Importa a classe SparkSession para criar uma sess√£o do Spark e interagir com DataFrames\n",
        "\n",
        "# Criar a sess√£o Spark\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"PySparkExample\") \\\n",
        "    .config(\"spark.driver.memory\", \"4g\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Verificar se a sess√£o foi criada corretamente\n",
        "print(\"Vers√£o do Spark:\", spark.version)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmt3_Tn6OnG7"
      },
      "outputs": [],
      "source": [
        "# Os\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9trpJPzwPO-4",
        "outputId": "32c6a2da-f5a2-4b51-dc4e-0626a0263e05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Montando o Google Drive no Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aud8cnn5b9Lw",
        "outputId": "c9e0330d-c868-430d-c193-dbce0afdfd4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cnae.parquet\n",
            "estab_unificado.parquet\n",
            "empresas_unificado.parquet\n",
            "motivos.parquet\n",
            "municipios.parquet\n",
            "natureza.parquet\n",
            "paises.parquet\n",
            "qualificacao.parquet\n",
            "simples.parquet\n",
            "socios_unificado.parquet\n",
            "socios_agrupado.parquet\n",
            "df_empresas_brasil_1\n",
            "df_empresas_brasil\n",
            "clusters_sample.parquet\n"
          ]
        }
      ],
      "source": [
        "# Identifica√ß√£o dos arquivos parquet no diret√≥rio\n",
        "\n",
        "#Lista arquivos do diret√≥rio\n",
        "\n",
        "files = os.listdir(\"/content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet\")\n",
        "\n",
        "# Exibe os arquivos\n",
        "for file in files:\n",
        "    print(file)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnwAvRfb2x_y",
        "outputId": "94b9b658-02f6-40e8-854a-afd101fc92cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Verificando cnpj_basico em dataframe com 60959932 linhas...\n",
            "  ‚Üí Valores √∫nicos: 60959931\n",
            "  ‚ö†Ô∏è H√° 1 duplicatas na chave 'cnpj_basico'!\n",
            "\n",
            "üîç Verificando cnpj_basico em dataframe com 64017368 linhas...\n",
            "  ‚Üí Valores √∫nicos: 60959931\n",
            "  ‚ö†Ô∏è H√° 3057437 duplicatas na chave 'cnpj_basico'!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Valida√ß√£o das chaves de jun√ß√£o\n",
        "\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "def verificar_duplicatas(df, chave):\n",
        "    total_linhas = df.count()\n",
        "    valores_unicos = df.select(chave).distinct().count()\n",
        "\n",
        "    print(f\"üîç Verificando {chave} em dataframe com {total_linhas} linhas...\")\n",
        "    print(f\"  ‚Üí Valores √∫nicos: {valores_unicos}\")\n",
        "\n",
        "    if valores_unicos < total_linhas:\n",
        "        print(f\"  ‚ö†Ô∏è H√° {total_linhas - valores_unicos} duplicatas na chave '{chave}'!\\n\")\n",
        "    else:\n",
        "        print(f\"  ‚úÖ Nenhuma duplicata encontrada na chave '{chave}'!\\n\")\n",
        "\n",
        "# Rodar para cada dataframe e chave\n",
        "verificar_duplicatas(empresas_unificado, \"cnpj_basico\")\n",
        "verificar_duplicatas(estab_unificado, \"cnpj_basico\")\n",
        "verificar_duplicatas(simples, \"cnpj_basico\")\n",
        "\n",
        "# Para df_socios, precisamos verificar m√∫ltiplas chaves\n",
        "for chave in [\"cnpj_basico\", \"array_nome_socio_pf_pj\", \"array_cpf_cnpj_socio\", \"array_cpf_representante_legal\", \"array_nome_representante\"]:\n",
        "    verificar_duplicatas(socios_agrupado, chave)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Codigo de jun√ß√£o sem gera√ß√£o do arquivo final\n",
        "\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import concat_ws, col, when, broadcast, lit\n",
        "from pyspark.sql.utils import AnalysisException\n",
        "import os\n",
        "import traceback\n",
        "\n",
        "# Configura√ß√µes de mem√≥ria do Spark\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Projeto ETL\") \\\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
        "    .config(\"spark.driver.memory\", \"8g\") \\\n",
        "    .config(\"spark.executor.memory\", \"4g\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Caminho do diret√≥rio no Google Drive\n",
        "drive_directory = \"/content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet\"\n",
        "\n",
        "# Lista de arquivos parquet\n",
        "arquivos_parquet = [\n",
        "    \"estab_unificado.parquet\",\n",
        "    \"empresas_unificado.parquet\",\n",
        "    \"simples.parquet\",\n",
        "    \"qualificacao.parquet\",\n",
        "    \"natureza.parquet\",\n",
        "    \"municipios.parquet\",\n",
        "    \"motivos.parquet\",\n",
        "    \"paises.parquet\",\n",
        "    \"cnae.parquet\",\n",
        "    \"socios_agrupado.parquet\"\n",
        "]\n",
        "\n",
        "# Configura√ß√µes otimizadas para PySpark\n",
        "spark.conf.set(\"spark.sql.parquet.compression.codec\", \"snappy\")\n",
        "spark.conf.set(\"spark.sql.parquet.mergeSchema\", \"false\")\n",
        "spark.conf.set(\"spark.sql.parquet.filterPushdown\", \"true\")\n",
        "spark.conf.set(\"spark.sql.files.maxPartitionBytes\", \"128m\")\n",
        "spark.conf.set(\"spark.sql.shuffle.partitions\", \"200\")\n",
        "\n",
        "# Fun√ß√£o para verificar se o arquivo parquet √© v√°lido\n",
        "def verificar_arquivo_parquet(caminho):\n",
        "    \"\"\"Verifica se um arquivo parquet pode ser lido corretamente.\"\"\"\n",
        "    try:\n",
        "        # Tenta ler apenas o esquema do arquivo, sem carregar dados\n",
        "        schema = spark.read.option(\"mergeSchema\", \"false\").parquet(caminho).schema\n",
        "        print(f\"Esquema do arquivo validado: {caminho}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao verificar esquema do arquivo {caminho}: {e}\")\n",
        "        return False\n",
        "\n",
        "# Dicion√°rio para armazenar os dataframes\n",
        "dataframes = {}\n",
        "\n",
        "total_linhas = 0  # Vari√°vel para armazenar o total de linhas\n",
        "\n",
        "# Loop para ler os arquivos parquet com tratamento de erros melhorado\n",
        "for arquivo in arquivos_parquet:\n",
        "    caminho_completo = f\"{drive_directory}/{arquivo}\"\n",
        "    df_name = arquivo.split(\".\")[0]\n",
        "\n",
        "    if os.path.exists(caminho_completo):\n",
        "        print(f\"Verificando arquivo: {caminho_completo}\")\n",
        "\n",
        "        # Verifica se o arquivo √© v√°lido antes de tentar carreg√°-lo\n",
        "        if verificar_arquivo_parquet(caminho_completo):\n",
        "            try:\n",
        "                # Tenta ler o arquivo sem contar as linhas inicialmente\n",
        "                print(f\"Carregando arquivo: {caminho_completo}\")\n",
        "                df = spark.read.option(\"mergeSchema\", \"false\").parquet(caminho_completo)\n",
        "\n",
        "                # Verifica se o DataFrame pode ser processado\n",
        "                try:\n",
        "                    # Tenta executar uma opera√ß√£o simples no DataFrame\n",
        "                    df.dtypes  # Isso n√£o executa um job Spark, apenas recupera metadados\n",
        "                    print(f\"Arquivo {arquivo} carregado com sucesso.\")\n",
        "\n",
        "                    # S√≥ cache se o DataFrame for usado nos joins\n",
        "                    if df_name in [\"estab_unificado\", \"socios_agrupado\", \"empresas_unificado\", \"simples\"]:\n",
        "                        df = df.cache()\n",
        "                        print(f\"DataFrame {df_name} colocado em cache.\")\n",
        "\n",
        "                    # Contagem de linhas com tratamento de erros\n",
        "                    try:\n",
        "                        print(f\"Contando linhas para {df_name}...\")\n",
        "                        num_linhas = df.count()\n",
        "                        total_linhas += num_linhas\n",
        "                        print(f\"Arquivo {arquivo} tem {num_linhas} linhas.\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"Erro ao contar linhas do arquivo {arquivo}: {e}\")\n",
        "                        print(f\"Detalhes do erro: {traceback.format_exc()}\")\n",
        "                        # Continua sem contar as linhas\n",
        "                        num_linhas = 0\n",
        "\n",
        "                    dataframes[df_name] = df\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Erro ao processar o DataFrame {df_name}: {e}\")\n",
        "                    print(f\"Detalhes do erro: {traceback.format_exc()}\")\n",
        "                    dataframes[df_name] = None\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Erro ao ler o arquivo {arquivo}: {e}\")\n",
        "                print(f\"Detalhes do erro: {traceback.format_exc()}\")\n",
        "                dataframes[df_name] = None\n",
        "        else:\n",
        "            print(f\"Arquivo {arquivo} n√£o p√¥de ser validado.\")\n",
        "            dataframes[df_name] = None\n",
        "    else:\n",
        "        print(f\"Arquivo n√£o encontrado: {caminho_completo}\")\n",
        "        dataframes[df_name] = None\n",
        "\n",
        "print(f\"Total estimado de linhas nos arquivos carregados: {total_linhas}\")\n",
        "\n",
        "# Verifica se o DataFrame principal foi carregado\n",
        "df_empresas_brasil = dataframes.get(\"estab_unificado\")\n",
        "\n",
        "if df_empresas_brasil is not None:\n",
        "    print(\"DataFrame estab_unificado carregado com sucesso. Prosseguindo com os joins.\")\n",
        "\n",
        "    # Lista de dataframes a serem unidos\n",
        "    dataframes_a_unir = [\"socios_agrupado\", \"empresas_unificado\", \"simples\"]\n",
        "    total_joins = len(dataframes_a_unir)\n",
        "\n",
        "    for i, df_name in enumerate(dataframes_a_unir):\n",
        "        df_atual = dataframes.get(df_name)\n",
        "        if df_atual is not None:\n",
        "            try:\n",
        "                # Verifica se a coluna de join existe\n",
        "                colunas_df_atual = df_atual.columns\n",
        "                if \"cnpj_basico\" in colunas_df_atual:\n",
        "                    try:\n",
        "                        # Executa o join com tratamento de erros\n",
        "                        print(f\"Iniciando join com {df_name}...\")\n",
        "                        df_empresas_brasil = df_empresas_brasil.join(df_atual, [\"cnpj_basico\"], \"left\")\n",
        "\n",
        "                        progresso = ((i + 1) / total_joins) * 100\n",
        "                        print(f\"Join com {df_name} conclu√≠do. Progresso: {progresso:.2f}%\")\n",
        "\n",
        "                        # Libera mem√≥ria do DataFrame que j√° foi usado no join\n",
        "                        try:\n",
        "                            df_atual.unpersist()\n",
        "                            print(f\"Mem√≥ria liberada para o DataFrame {df_name}\")\n",
        "                        except:\n",
        "                            print(f\"N√£o foi poss√≠vel liberar a mem√≥ria para {df_name}\")\n",
        "\n",
        "                        dataframes[df_name] = None\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"Erro ao realizar join com {df_name}: {e}\")\n",
        "                        print(f\"Detalhes do erro: {traceback.format_exc()}\")\n",
        "                else:\n",
        "                    print(f\"DataFrame {df_name} n√£o cont√©m a coluna 'cnpj_basico'. Join ignorado.\")\n",
        "                    print(f\"Colunas dispon√≠veis: {colunas_df_atual}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Erro ao processar o DataFrame {df_name} para join: {e}\")\n",
        "                print(f\"Detalhes do erro: {traceback.format_exc()}\")\n",
        "        else:\n",
        "            print(f\"DataFrame {df_name} n√£o encontrado, join ignorado.\")\n",
        "\n",
        "    # Reutiliza os DataFrames carregados anteriormente para os joins adicionais\n",
        "    df_motivos = dataframes.get(\"motivos\")\n",
        "    df_paises = dataframes.get(\"paises\")\n",
        "    df_cnae = dataframes.get(\"cnae\")\n",
        "    df_municipios = dataframes.get(\"municipios\")\n",
        "    df_natureza = dataframes.get(\"natureza\")\n",
        "    df_qualificacao = dataframes.get(\"qualificacao\")\n",
        "\n",
        "    # 1. Concatenar as colunas referentes ao CNPJ\n",
        "    df_empresas_brasil = df_empresas_brasil.withColumn(\"cnpj\", concat_ws(\"\", col(\"cnpj_basico\"), col(\"cnpj_ordem\"), col(\"cnpj_dv\")))\n",
        "\n",
        "    # 2. Identificar a situa√ß√£o cadastral\n",
        "    df_empresas_brasil = df_empresas_brasil.withColumn(\"sit_cadastral\",\n",
        "        when(col(\"cod_sit_cadastral\") == \"01\", \"NULA\")\n",
        "        .when(col(\"cod_sit_cadastral\") == \"02\", \"ATIVA\")\n",
        "        .when(col(\"cod_sit_cadastral\") == \"03\", \"SUSPENSA\")\n",
        "        .when(col(\"cod_sit_cadastral\") == \"04\", \"INAPTA\")\n",
        "        .when(col(\"cod_sit_cadastral\") == \"08\", \"BAIXADA\")\n",
        "        .otherwise(\"DESCONHECIDA\")\n",
        "    )\n",
        "\n",
        "    # 3. Identificar o motivo da situa√ß√£o cadastral (com tratamento de nulos)\n",
        "    df_empresas_brasil = (\n",
        "        df_empresas_brasil\n",
        "        .join(broadcast(df_motivos), df_empresas_brasil[\"cod_mot_sit_cadastral\"] == df_motivos[\"cod_motivo\"], \"left\")\n",
        "        .drop(\"cod_mot_sit_cadastral\")\n",
        "        .withColumnRenamed(\"descricao_motivo\", \"motivo_sit_cadastral\")\n",
        "        .na.fill({\"motivo_sit_cadastral\": \"SEM MOTIVO\"})\n",
        "    )\n",
        "\n",
        "    # 4. Identificar o pa√≠s (com tratamento de nulos e broadcast join)\n",
        "    df_empresas_brasil = (\n",
        "        df_empresas_brasil\n",
        "        .join(broadcast(df_paises), df_empresas_brasil[\"cod_pais\"] == df_paises[\"cod_pais\"], \"left\")\n",
        "        .drop(\"cod_pais\")\n",
        "        .withColumnRenamed(\"nome_pais\", \"pais\")\n",
        "        .na.fill({\"pais\": \"N√ÉO APLICADO\"})\n",
        "    )\n",
        "\n",
        "    # 5. Identificar a CNAE principal (com tratamento de nulos e broadcast join)\n",
        "    df_empresas_brasil = (\n",
        "        df_empresas_brasil\n",
        "        .join(broadcast(df_cnae), df_empresas_brasil[\"cnae_fiscal_principal\"] == df_cnae[\"cod_cnae\"], \"left\")\n",
        "        .drop(\"cnae_fiscal_principal\")\n",
        "        .withColumnRenamed(\"descricao\", \"cnae_principal\")\n",
        "        .na.fill({\"cnae_principal\": \"CNAE PRINCIPAL DESCONHECIDO\"})\n",
        "    )\n",
        "\n",
        "    # 6. Identificar o munic√≠pio (com tratamento de nulos e broadcast join)\n",
        "    df_empresas_brasil = (\n",
        "        df_empresas_brasil\n",
        "        .join(broadcast(df_municipios), df_empresas_brasil[\"municipio\"] == df_municipios[\"cod_municipio\"], \"left\")\n",
        "        .drop(\"municipio\")\n",
        "        .withColumnRenamed(\"nome_municipio\", \"municipio\")\n",
        "        .na.fill({\"municipio\": \"MUNIC√çPIO DESCONHECIDO\"})\n",
        "    )\n",
        "\n",
        "    # 7. Identificar a natureza jur√≠dica (com tratamento de nulos e broadcast join)\n",
        "    df_empresas_brasil = (\n",
        "        df_empresas_brasil\n",
        "        .join(broadcast(df_natureza), df_empresas_brasil[\"cod_nat_juridica\"] == df_natureza[\"cod_nat_juridica\"], \"left\")\n",
        "        .drop(\"cod_nat_juridica\")\n",
        "        .withColumnRenamed(\"nome_nat_juridica\", \"nat_juridica\")\n",
        "        .na.fill({\"nat_juridica\": \"NAT JUR√çDICA DESC\"})\n",
        "    )\n",
        "\n",
        "    # 8. Identificar a qualifica√ß√£o do respons√°vel (com tratamento de nulos e broadcast join)\n",
        "    df_empresas_brasil = (\n",
        "        df_empresas_brasil\n",
        "        .join(broadcast(df_qualificacao), df_empresas_brasil[\"cod_qualificacao_responsavel\"] == df_qualificacao[\"cod_quali_socio\"], \"left\")\n",
        "        .drop(\"cod_qualificacao_responsavel\")\n",
        "        .withColumnRenamed(\"nome_quali_socio\", \"qualificacao_responsavel\")\n",
        "        .na.fill({\"qualificacao_responsavel\": \"DESCONHECIDA\"})\n",
        "    )\n",
        "\n",
        "    print(\"Jun√ß√µes realizadas com sucesso.\")\n",
        "\n",
        "else:\n",
        "    print(\"DataFrame estab_unificado n√£o encontrado. Verifique a leitura dos arquivos.\")\n",
        "\n",
        "\n",
        "# Mostra algumas linhas do DataFrame final para inspe√ß√£o\n",
        "df_empresas_brasil.show(5)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OyLQlApAKbP",
        "outputId": "208e9c2b-98e5-4618-f48f-96a8d9378969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verificando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/estab_unificado.parquet\n",
            "Esquema do arquivo validado: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/estab_unificado.parquet\n",
            "Carregando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/estab_unificado.parquet\n",
            "Arquivo estab_unificado.parquet carregado com sucesso.\n",
            "DataFrame estab_unificado colocado em cache.\n",
            "Contando linhas para estab_unificado...\n",
            "Arquivo estab_unificado.parquet tem 64017368 linhas.\n",
            "Verificando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/empresas_unificado.parquet\n",
            "Esquema do arquivo validado: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/empresas_unificado.parquet\n",
            "Carregando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/empresas_unificado.parquet\n",
            "Arquivo empresas_unificado.parquet carregado com sucesso.\n",
            "DataFrame empresas_unificado colocado em cache.\n",
            "Contando linhas para empresas_unificado...\n",
            "Arquivo empresas_unificado.parquet tem 60959932 linhas.\n",
            "Verificando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/simples.parquet\n",
            "Esquema do arquivo validado: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/simples.parquet\n",
            "Carregando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/simples.parquet\n",
            "Arquivo simples.parquet carregado com sucesso.\n",
            "DataFrame simples colocado em cache.\n",
            "Contando linhas para simples...\n",
            "Arquivo simples.parquet tem 41720964 linhas.\n",
            "Verificando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/qualificacao.parquet\n",
            "Esquema do arquivo validado: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/qualificacao.parquet\n",
            "Carregando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/qualificacao.parquet\n",
            "Arquivo qualificacao.parquet carregado com sucesso.\n",
            "Contando linhas para qualificacao...\n",
            "Arquivo qualificacao.parquet tem 68 linhas.\n",
            "Verificando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/natureza.parquet\n",
            "Esquema do arquivo validado: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/natureza.parquet\n",
            "Carregando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/natureza.parquet\n",
            "Arquivo natureza.parquet carregado com sucesso.\n",
            "Contando linhas para natureza...\n",
            "Arquivo natureza.parquet tem 90 linhas.\n",
            "Verificando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/municipios.parquet\n",
            "Esquema do arquivo validado: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/municipios.parquet\n",
            "Carregando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/municipios.parquet\n",
            "Arquivo municipios.parquet carregado com sucesso.\n",
            "Contando linhas para municipios...\n",
            "Arquivo municipios.parquet tem 5571 linhas.\n",
            "Verificando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/motivos.parquet\n",
            "Esquema do arquivo validado: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/motivos.parquet\n",
            "Carregando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/motivos.parquet\n",
            "Arquivo motivos.parquet carregado com sucesso.\n",
            "Contando linhas para motivos...\n",
            "Arquivo motivos.parquet tem 61 linhas.\n",
            "Verificando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/paises.parquet\n",
            "Esquema do arquivo validado: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/paises.parquet\n",
            "Carregando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/paises.parquet\n",
            "Arquivo paises.parquet carregado com sucesso.\n",
            "Contando linhas para paises...\n",
            "Arquivo paises.parquet tem 255 linhas.\n",
            "Verificando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/cnae.parquet\n",
            "Esquema do arquivo validado: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/cnae.parquet\n",
            "Carregando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/cnae.parquet\n",
            "Arquivo cnae.parquet carregado com sucesso.\n",
            "Contando linhas para cnae...\n",
            "Arquivo cnae.parquet tem 1359 linhas.\n",
            "Verificando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/socios_agrupado.parquet\n",
            "Esquema do arquivo validado: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/socios_agrupado.parquet\n",
            "Carregando arquivo: /content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet/socios_agrupado.parquet\n",
            "Arquivo socios_agrupado.parquet carregado com sucesso.\n",
            "DataFrame socios_agrupado colocado em cache.\n",
            "Contando linhas para socios_agrupado...\n",
            "Arquivo socios_agrupado.parquet tem 14443458 linhas.\n",
            "Total estimado de linhas nos arquivos carregados: 181149126\n",
            "DataFrame estab_unificado carregado com sucesso. Prosseguindo com os joins.\n",
            "Iniciando join com socios_agrupado...\n",
            "Join com socios_agrupado conclu√≠do. Progresso: 33.33%\n",
            "Mem√≥ria liberada para o DataFrame socios_agrupado\n",
            "Iniciando join com empresas_unificado...\n",
            "Join com empresas_unificado conclu√≠do. Progresso: 66.67%\n",
            "Mem√≥ria liberada para o DataFrame empresas_unificado\n",
            "Iniciando join com simples...\n",
            "Join com simples conclu√≠do. Progresso: 100.00%\n",
            "Mem√≥ria liberada para o DataFrame simples\n",
            "Jun√ß√µes realizadas com sucesso.\n",
            "+-----------+----------+-------+----------------+--------------------+-----------------+------------------+---------------+---------------------+----------------------+--------------+--------------------+------+--------------------+-----------------+--------+---+-----+--------+-----+--------+-------+-------+--------------------+-----------------+----------------------+------------------+----------------------+--------------------+---------------------+----------------------------+--------------------+-----------------------------+------------------------+-----------------------------+----------------------+----------------------+--------------------+--------------+-----------------+--------------------+-------------+------------------+-----------------+---------+--------------+-------------+--------------+-------------+----------+--------------------+------------+--------+--------------------+-------------+-------------+--------------------+---------------+------------------------+\n",
            "|cnpj_basico|cnpj_ordem|cnpj_dv|id_matriz_filial|       nome_fantasia|cod_sit_cadastral|data_sit_cadastral|nome_cidade_ext|data_inicio_atividade|cnae_fiscal_secundaria|tipo_de_lograd|          logradouro|numero|         complemento|           bairro|     cep| uf|ddd_1|   tel_1|ddd_2|   tel_2|ddd_fax|num_fax|  correio_eletronico|situacao_especial|data_situacao_especial|array_cod_id_socio|array_nome_socio_pf_pj|array_cpf_cnpj_socio|array_cod_quali_socio|array_data_entrada_sociedade|array_cod_pais_socio|array_cpf_representante_legal|array_nome_representante|array_cod_quali_representante|array_cod_faixa_etaria|array_nome_quali_socio|        razao_social|capital_social|cod_porte_empresa|ente_federativo_resp|opcao_simples|data_opcao_simples|data_excl_simples|opcao_mei|data_opcao_mei|data_excl_mei|          cnpj|sit_cadastral|cod_motivo|motivo_sit_cadastral|        pais|cod_cnae|      cnae_principal|cod_municipio|    municipio|        nat_juridica|cod_quali_socio|qualificacao_responsavel|\n",
            "+-----------+----------+-------+----------------+--------------------+-----------------+------------------+---------------+---------------------+----------------------+--------------+--------------------+------+--------------------+-----------------+--------+---+-----+--------+-----+--------+-------+-------+--------------------+-----------------+----------------------+------------------+----------------------+--------------------+---------------------+----------------------------+--------------------+-----------------------------+------------------------+-----------------------------+----------------------+----------------------+--------------------+--------------+-----------------+--------------------+-------------+------------------+-----------------+---------+--------------+-------------+--------------+-------------+----------+--------------------+------------+--------+--------------------+-------------+-------------+--------------------+---------------+------------------------+\n",
            "|   54140564|      0001|     59|               1|                NULL|               08|          20240425|           NULL|             20240301|       4930204,4930201|       AVENIDA|               ARAXA|   236|                NULL|JARDIM VERDE VIDA|76888000| RO|   69|93242103| NULL|    NULL|   NULL|   NULL|SILVAPEREIRAALINE...|             NULL|                  NULL|              NULL|                  NULL|                NULL|                 NULL|                        NULL|                NULL|                         NULL|                    NULL|                         NULL|                  NULL|                  NULL|54.140.564 ALINE ...|      10000,00|               01|                NULL|            N|          20240301|         20240425|        N|      20240301|     20240425|54140564000159|      BAIXADA|        01|EXTINCAO POR ENCE...|N√ÉO APLICADO| 4930202|Transporte rodovi...|         0685|  MONTE NEGRO|Empres√°rio (Indiv...|             50|              Empres√°rio|\n",
            "|   13587990|      0001|     58|               1|                NULL|               02|          20110503|           NULL|             20110503|       4781400,9602501|       AVENIDA|DOUTOR JOSE THOMA...|    57|                NULL|       FAROLANDIA|49030270| SE|   79|98320369| NULL|    NULL|   NULL|   NULL|FALECONOSCO.JOSYC...|             NULL|                  NULL|              NULL|                  NULL|                NULL|                 NULL|                        NULL|                NULL|                         NULL|                    NULL|                         NULL|                  NULL|                  NULL|13.587.990 JOSENI...|      30000,00|               01|                NULL|            N|          20110503|         20241231|        N|      20110503|     20241231|13587990000158|        ATIVA|        00|          SEM MOTIVO|N√ÉO APLICADO| 4772500|Com√©rcio varejist...|         3105|      ARACAJU|Empres√°rio (Indiv...|             50|              Empres√°rio|\n",
            "|   53782995|      0001|     56|               1|       MCR DO BRASIL|               02|          20240202|           NULL|             20240202|  6311900,6319400,6...|       AVENIDA|            PAULISTA|  1106|SALA  01         ...|       BELA VISTA|01310914| SP|   41|98880068| 0000|00000000|   NULL|   NULL|ABERTURA@CONTABIL...|             NULL|                  NULL|               [2]|  [MARCELO DA CONCE...|       [***042907**]|                 [49]|                  [20240202]|                  []|                [***000000**]|                      []|                         [00]|                   [5]|  [S√≥cio-Administra...|GLOBAL TECNOLOGIA...|      12000,00|               01|                NULL|            S|          20240202|         00000000|        N|      00000000|     00000000|53782995000156|        ATIVA|        00|          SEM MOTIVO|      BRASIL| 6204000|Consultoria em te...|         7107|    SAO PAULO|Sociedade Empres√°...|             49|     S√≥cio-Administrador|\n",
            "|   40310289|      0001|     60|               1|                NULL|               02|          20190606|           NULL|             20190606|                  NULL|           RUA|BELARMINO DE MEND...|   107|           SALA  102|           CENTRO|85851100| PR|   45|30290465| NULL|    NULL|   NULL|   NULL|                NULL|             NULL|                  NULL|            [2, 2]|  [SANDRA ALVES GOG...|[***948169**, ***...|             [49, 49]|        [20190606, 20190606]|                  []|         [***000000**, ***...|                      []|                     [00, 00]|                [4, 5]|  [S√≥cio-Administra...|BITTENCOURT & GOG...|       2000,00|               01|                NULL|            S|          20240101|         00000000|        N|      00000000|     00000000|40310289000160|        ATIVA|        00|          SEM MOTIVO|N√ÉO APLICADO| 6911701|Servi√ßos advocat√≠...|         7563|FOZ DO IGUACU|Sociedade Simples...|             49|     S√≥cio-Administrador|\n",
            "|   35005578|      0001|     15|               1|LANCHONETE ESCORPIAO|               08|          20000519|           NULL|             19891003|                  NULL|       AVENIDA|   SARGENTO HERMINIO|  1755|                NULL|      SAO VICENTE|63700001| CE| NULL|    NULL| NULL|    NULL|   NULL|   NULL|                NULL|             NULL|                  NULL|              NULL|                  NULL|                NULL|                 NULL|                        NULL|                NULL|                         NULL|                    NULL|                         NULL|                  NULL|                  NULL|MARIA DE PAULA PO...|          0,00|               05|                NULL|         NULL|              NULL|             NULL|     NULL|          NULL|         NULL|35005578000115|      BAIXADA|        01|EXTINCAO POR ENCE...|N√ÉO APLICADO| 4723700|Com√©rcio varejist...|         1383|      CRATEUS|Empres√°rio (Indiv...|             50|              Empres√°rio|\n",
            "+-----------+----------+-------+----------------+--------------------+-----------------+------------------+---------------+---------------------+----------------------+--------------+--------------------+------+--------------------+-----------------+--------+---+-----+--------+-----+--------+-------+-------+--------------------+-----------------+----------------------+------------------+----------------------+--------------------+---------------------+----------------------------+--------------------+-----------------------------+------------------------+-----------------------------+----------------------+----------------------+--------------------+--------------+-----------------+--------------------+-------------+------------------+-----------------+---------+--------------+-------------+--------------+-------------+----------+--------------------+------------+--------+--------------------+-------------+-------------+--------------------+---------------+------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gHiWGJEXAt6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t31AHJMFAt04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AESfAyubAtuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# C√≥digo de jun√ß√£o com a gera√ß√£o do arquivo particionado do dataframe final df_empresas_brasil\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import concat_ws, col, when, broadcast, lit\n",
        "from pyspark.sql.utils import AnalysisException\n",
        "import os\n",
        "import traceback\n",
        "\n",
        "# Configura√ß√µes de mem√≥ria do Spark\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Projeto ETL\") \\\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
        "    .config(\"spark.driver.memory\", \"8g\") \\\n",
        "    .config(\"spark.executor.memory\", \"4g\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Caminho do diret√≥rio no Google Drive\n",
        "drive_directory = \"/content/drive/MyDrive/Projeto_ETL_Trust_Works/Dados_abertos/parquet\"\n",
        "\n",
        "# Lista de arquivos parquet\n",
        "arquivos_parquet = [\n",
        "    \"estab_unificado.parquet\",\n",
        "    \"empresas_unificado.parquet\",\n",
        "    \"simples.parquet\",\n",
        "    \"qualificacao.parquet\",\n",
        "    \"natureza.parquet\",\n",
        "    \"municipios.parquet\",\n",
        "    \"motivos.parquet\",\n",
        "    \"paises.parquet\",\n",
        "    \"cnae.parquet\",\n",
        "    \"socios_agrupado.parquet\"\n",
        "]\n",
        "\n",
        "# Configura√ß√µes otimizadas para PySpark\n",
        "spark.conf.set(\"spark.sql.parquet.compression.codec\", \"snappy\")\n",
        "spark.conf.set(\"spark.sql.parquet.mergeSchema\", \"false\")\n",
        "spark.conf.set(\"spark.sql.parquet.filterPushdown\", \"true\")\n",
        "spark.conf.set(\"spark.sql.files.maxPartitionBytes\", \"128m\")\n",
        "spark.conf.set(\"spark.sql.shuffle.partitions\", \"200\")\n",
        "\n",
        "# Fun√ß√£o para verificar se o arquivo parquet √© v√°lido\n",
        "def verificar_arquivo_parquet(caminho):\n",
        "    \"\"\"Verifica se um arquivo parquet pode ser lido corretamente.\"\"\"\n",
        "    try:\n",
        "        # Tenta ler apenas o esquema do arquivo, sem carregar dados\n",
        "        schema = spark.read.option(\"mergeSchema\", \"false\").parquet(caminho).schema\n",
        "        print(f\"Esquema do arquivo validado: {caminho}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao verificar esquema do arquivo {caminho}: {e}\")\n",
        "        return False\n",
        "\n",
        "# Dicion√°rio para armazenar os dataframes\n",
        "dataframes = {}\n",
        "\n",
        "total_linhas = 0  # Vari√°vel para armazenar o total de linhas\n",
        "\n",
        "# Loop para ler os arquivos parquet com tratamento de erros melhorado\n",
        "for arquivo in arquivos_parquet:\n",
        "    caminho_completo = f\"{drive_directory}/{arquivo}\"\n",
        "    df_name = arquivo.split(\".\")[0]\n",
        "\n",
        "    if os.path.exists(caminho_completo):\n",
        "        print(f\"Verificando arquivo: {caminho_completo}\")\n",
        "\n",
        "        # Verifica se o arquivo √© v√°lido antes de tentar carreg√°-lo\n",
        "        if verificar_arquivo_parquet(caminho_completo):\n",
        "            try:\n",
        "                # Tenta ler o arquivo sem contar as linhas inicialmente\n",
        "                print(f\"Carregando arquivo: {caminho_completo}\")\n",
        "                df = spark.read.option(\"mergeSchema\", \"false\").parquet(caminho_completo)\n",
        "\n",
        "                # Verifica se o DataFrame pode ser processado\n",
        "                try:\n",
        "                    # Tenta executar uma opera√ß√£o simples no DataFrame\n",
        "                    df.dtypes  # Isso n√£o executa um job Spark, apenas recupera metadados\n",
        "                    print(f\"Arquivo {arquivo} carregado com sucesso.\")\n",
        "\n",
        "                    # S√≥ cache se o DataFrame for usado nos joins\n",
        "                    if df_name in [\"estab_unificado\", \"socios_agrupado\", \"empresas_unificado\", \"simples\"]:\n",
        "                        df = df.cache()\n",
        "                        print(f\"DataFrame {df_name} colocado em cache.\")\n",
        "\n",
        "                    # Contagem de linhas com tratamento de erros\n",
        "                    try:\n",
        "                        print(f\"Contando linhas para {df_name}...\")\n",
        "                        num_linhas = df.count()\n",
        "                        total_linhas += num_linhas\n",
        "                        print(f\"Arquivo {arquivo} tem {num_linhas} linhas.\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"Erro ao contar linhas do arquivo {arquivo}: {e}\")\n",
        "                        print(f\"Detalhes do erro: {traceback.format_exc()}\")\n",
        "                        # Continua sem contar as linhas\n",
        "                        num_linhas = 0\n",
        "\n",
        "                    dataframes[df_name] = df\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Erro ao processar o DataFrame {df_name}: {e}\")\n",
        "                    print(f\"Detalhes do erro: {traceback.format_exc()}\")\n",
        "                    dataframes[df_name] = None\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Erro ao ler o arquivo {arquivo}: {e}\")\n",
        "                print(f\"Detalhes do erro: {traceback.format_exc()}\")\n",
        "                dataframes[df_name] = None\n",
        "        else:\n",
        "            print(f\"Arquivo {arquivo} n√£o p√¥de ser validado.\")\n",
        "            dataframes[df_name] = None\n",
        "    else:\n",
        "        print(f\"Arquivo n√£o encontrado: {caminho_completo}\")\n",
        "        dataframes[df_name] = None\n",
        "\n",
        "print(f\"Total estimado de linhas nos arquivos carregados: {total_linhas}\")\n",
        "\n",
        "# Verifica se o DataFrame principal foi carregado\n",
        "df_empresas_brasil = dataframes.get(\"estab_unificado\")\n",
        "\n",
        "if df_empresas_brasil is not None:\n",
        "    print(\"DataFrame estab_unificado carregado com sucesso. Prosseguindo com os joins.\")\n",
        "\n",
        "    # Lista de dataframes a serem unidos\n",
        "    dataframes_a_unir = [\"socios_agrupado\", \"empresas_unificado\", \"simples\"]\n",
        "    total_joins = len(dataframes_a_unir)\n",
        "\n",
        "    for i, df_name in enumerate(dataframes_a_unir):\n",
        "        df_atual = dataframes.get(df_name)\n",
        "        if df_atual is not None:\n",
        "            try:\n",
        "                # Verifica se a coluna de join existe\n",
        "                colunas_df_atual = df_atual.columns\n",
        "                if \"cnpj_basico\" in colunas_df_atual:\n",
        "                    try:\n",
        "                        # Executa o join com tratamento de erros\n",
        "                        print(f\"Iniciando join com {df_name}...\")\n",
        "                        df_empresas_brasil = df_empresas_brasil.join(df_atual, [\"cnpj_basico\"], \"left\")\n",
        "\n",
        "                        progresso = ((i + 1) / total_joins) * 100\n",
        "                        print(f\"Join com {df_name} conclu√≠do. Progresso: {progresso:.2f}%\")\n",
        "\n",
        "                        # Libera mem√≥ria do DataFrame que j√° foi usado no join\n",
        "                        try:\n",
        "                            df_atual.unpersist()\n",
        "                            print(f\"Mem√≥ria liberada para o DataFrame {df_name}\")\n",
        "                        except:\n",
        "                            print(f\"N√£o foi poss√≠vel liberar a mem√≥ria para {df_name}\")\n",
        "\n",
        "                        dataframes[df_name] = None\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"Erro ao realizar join com {df_name}: {e}\")\n",
        "                        print(f\"Detalhes do erro: {traceback.format_exc()}\")\n",
        "                else:\n",
        "                    print(f\"DataFrame {df_name} n√£o cont√©m a coluna 'cnpj_basico'. Join ignorado.\")\n",
        "                    print(f\"Colunas dispon√≠veis: {colunas_df_atual}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Erro ao processar o DataFrame {df_name} para join: {e}\")\n",
        "                print(f\"Detalhes do erro: {traceback.format_exc()}\")\n",
        "        else:\n",
        "            print(f\"DataFrame {df_name} n√£o encontrado, join ignorado.\")\n",
        "\n",
        "    # Reutiliza os DataFrames carregados anteriormente para os joins adicionais\n",
        "    df_motivos = dataframes.get(\"motivos\")\n",
        "    df_paises = dataframes.get(\"paises\")\n",
        "    df_cnae = dataframes.get(\"cnae\")\n",
        "    df_municipios = dataframes.get(\"municipios\")\n",
        "    df_natureza = dataframes.get(\"natureza\")\n",
        "    df_qualificacao = dataframes.get(\"qualificacao\")\n",
        "\n",
        "    # 1. Concatenar as colunas referentes ao CNPJ\n",
        "    df_empresas_brasil = df_empresas_brasil.withColumn(\"cnpj\", concat_ws(\"\", col(\"cnpj_basico\"), col(\"cnpj_ordem\"), col(\"cnpj_dv\")))\n",
        "\n",
        "    # 2. Identificar a situa√ß√£o cadastral\n",
        "    df_empresas_brasil = df_empresas_brasil.withColumn(\"sit_cadastral\",\n",
        "        when(col(\"cod_sit_cadastral\") == \"01\", \"NULA\")\n",
        "        .when(col(\"cod_sit_cadastral\") == \"02\", \"ATIVA\")\n",
        "        .when(col(\"cod_sit_cadastral\") == \"03\", \"SUSPENSA\")\n",
        "        .when(col(\"cod_sit_cadastral\") == \"04\", \"INAPTA\")\n",
        "        .when(col(\"cod_sit_cadastral\") == \"08\", \"BAIXADA\")\n",
        "        .otherwise(\"DESCONHECIDA\")\n",
        "    )\n",
        "\n",
        "    # 3. Identificar o motivo da situa√ß√£o cadastral (com tratamento de nulos)\n",
        "    df_empresas_brasil = (\n",
        "        df_empresas_brasil\n",
        "        .join(broadcast(df_motivos), df_empresas_brasil[\"cod_mot_sit_cadastral\"] == df_motivos[\"cod_motivo\"], \"left\")\n",
        "        .drop(\"cod_mot_sit_cadastral\")\n",
        "        .withColumnRenamed(\"descricao_motivo\", \"motivo_sit_cadastral\")\n",
        "        .na.fill({\"motivo_sit_cadastral\": \"SEM MOTIVO\"})\n",
        "    )\n",
        "\n",
        "    # 4. Identificar o pa√≠s (com tratamento de nulos e broadcast join)\n",
        "    df_empresas_brasil = (\n",
        "        df_empresas_brasil\n",
        "        .join(broadcast(df_paises), df_empresas_brasil[\"cod_pais\"] == df_paises[\"cod_pais\"], \"left\")\n",
        "        .drop(\"cod_pais\")\n",
        "        .withColumnRenamed(\"nome_pais\", \"pais\")\n",
        "        .na.fill({\"pais\": \"N√ÉO APLICADO\"})\n",
        "    )\n",
        "\n",
        "    # 5. Identificar a CNAE principal (com tratamento de nulos e broadcast join)\n",
        "    df_empresas_brasil = (\n",
        "        df_empresas_brasil\n",
        "        .join(broadcast(df_cnae), df_empresas_brasil[\"cnae_fiscal_principal\"] == df_cnae[\"cod_cnae\"], \"left\")\n",
        "        .drop(\"cnae_fiscal_principal\")\n",
        "        .withColumnRenamed(\"descricao\", \"cnae_principal\")\n",
        "        .na.fill({\"cnae_principal\": \"CNAE PRINCIPAL DESCONHECIDO\"})\n",
        "    )\n",
        "\n",
        "    # 6. Identificar o munic√≠pio (com tratamento de nulos e broadcast join)\n",
        "    df_empresas_brasil = (\n",
        "        df_empresas_brasil\n",
        "        .join(broadcast(df_municipios), df_empresas_brasil[\"municipio\"] == df_municipios[\"cod_municipio\"], \"left\")\n",
        "        .drop(\"municipio\")\n",
        "        .withColumnRenamed(\"nome_municipio\", \"municipio\")\n",
        "        .na.fill({\"municipio\": \"MUNIC√çPIO DESCONHECIDO\"})\n",
        "    )\n",
        "\n",
        "    # 7. Identificar a natureza jur√≠dica (com tratamento de nulos e broadcast join)\n",
        "    df_empresas_brasil = (\n",
        "        df_empresas_brasil\n",
        "        .join(broadcast(df_natureza), df_empresas_brasil[\"cod_nat_juridica\"] == df_natureza[\"cod_nat_juridica\"], \"left\")\n",
        "        .drop(\"cod_nat_juridica\")\n",
        "        .withColumnRenamed(\"nome_nat_juridica\", \"nat_juridica\")\n",
        "        .na.fill({\"nat_juridica\": \"NAT JUR√çDICA DESC\"})\n",
        "    )\n",
        "\n",
        "    # 8. Identificar a qualifica√ß√£o do respons√°vel (com tratamento de nulos e broadcast join)\n",
        "    df_empresas_brasil = (\n",
        "        df_empresas_brasil\n",
        "        .join(broadcast(df_qualificacao), df_empresas_brasil[\"cod_qualificacao_responsavel\"] == df_qualificacao[\"cod_quali_socio\"], \"left\")\n",
        "        .drop(\"cod_qualificacao_responsavel\")\n",
        "        .withColumnRenamed(\"nome_quali_socio\", \"qualificacao_responsavel\")\n",
        "        .na.fill({\"qualificacao_responsavel\": \"DESCONHECIDA\"})\n",
        "    )\n",
        "\n",
        "    # Salvamento do DataFrame final\n",
        "    output_path = f\"{drive_directory}/df_empresas_brasil\"\n",
        "\n",
        "    # Reparticionamento e salvamento\n",
        "    df_empresas_brasil.repartition(200) \\\n",
        "        .write \\\n",
        "        .mode(\"overwrite\") \\\n",
        "        .option(\"compression\", \"snappy\") \\\n",
        "        .parquet(output_path)\n",
        "\n",
        "    print(f\"DataFrame final salvo com sucesso em: {output_path}\")\n",
        "\n",
        "    # Libera mem√≥ria dos DataFrames lidos\n",
        "    for df_name, df in dataframes.items():\n",
        "        if df is not None:\n",
        "            try:\n",
        "                df.unpersist()\n",
        "                print(f\"Mem√≥ria liberada para o DataFrame {df_name}\")\n",
        "            except:\n",
        "                pass\n",
        "else:\n",
        "    print(\"DataFrame estab_unificado n√£o encontrado. Verifique a leitura dos arquivos.\")"
      ],
      "metadata": {
        "id": "H1SpNkV3AKYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostra algumas linhas do DataFrame final para inspe√ß√£o\n",
        "df_empresas_brasil.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoJS4QAyFZob",
        "outputId": "b250d7e3-0935-4914-894b-295e1cd7e981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+-------+----------------+--------------------+-----------------+------------------+---------------------+---------------+------------+---------------------+---------------------+----------------------+--------------+--------------------+------+--------------------+-----------------+--------+---+---------+------------+------------+------------+------------+------------+------------+--------------------+-----------------+----------------------+------------------+----------------------+--------------------+---------------------+----------------------------+--------------------+-----------------------------+------------------------+-----------------------------+----------------------+----------------------+--------------------+----------------+----------------------------+--------------+-----------------+--------------------+-------------+------------------+-----------------+------------+--------------+-------------+\n",
            "|cnpj_basico|cnpj_ordem|cnpj_dv|id_matriz_filial|       nome_fantasia|cod_sit_cadastral|data_sit_cadastral|cod_mot_sit_cadastral|nome_cidade_ext|    cod_pais|data_inicio_atividade|cnae_fiscal_principal|cnae_fiscal_secundaria|tipo_de_lograd|          logradouro|numero|         complemento|           bairro|     cep| uf|municipio|       ddd_1|       tel_1|       ddd_2|       tel_2|     ddd_fax|     num_fax|  correio_eletronico|situacao_especial|data_situacao_especial|array_cod_id_socio|array_nome_socio_pf_pj|array_cpf_cnpj_socio|array_cod_quali_socio|array_data_entrada_sociedade|array_cod_pais_socio|array_cpf_representante_legal|array_nome_representante|array_cod_quali_representante|array_cod_faixa_etaria|array_nome_quali_socio|        razao_social|cod_nat_juridica|cod_qualificacao_responsavel|capital_social|cod_porte_empresa|ente_federativo_resp|opcao_simples|data_opcao_simples|data_excl_simples|   opcao_mei|data_opcao_mei|data_excl_mei|\n",
            "+-----------+----------+-------+----------------+--------------------+-----------------+------------------+---------------------+---------------+------------+---------------------+---------------------+----------------------+--------------+--------------------+------+--------------------+-----------------+--------+---+---------+------------+------------+------------+------------+------------+------------+--------------------+-----------------+----------------------+------------------+----------------------+--------------------+---------------------+----------------------------+--------------------+-----------------------------+------------------------+-----------------------------+----------------------+----------------------+--------------------+----------------+----------------------------+--------------+-----------------+--------------------+-------------+------------------+-----------------+------------+--------------+-------------+\n",
            "|   54140564|      0001|     59|               1|        N√£o aplicado|               08|          20240425|                   01|   N√£o aplicado|N√£o aplicado|             20240301|              4930202|       4930204,4930201|       AVENIDA|               ARAXA|   236|        N√£o aplicado|JARDIM VERDE VIDA|76888000| RO|     0685|          69|    93242103|N√£o aplicado|N√£o aplicado|N√£o aplicado|N√£o aplicado|SILVAPEREIRAALINE...|     N√£o aplicado|          N√£o aplicado|              NULL|                  NULL|                NULL|                 NULL|                        NULL|                NULL|                         NULL|                    NULL|                         NULL|                  NULL|                  NULL|54.140.564 ALINE ...|            2135|                          50|      10000,00|               01|        N√£o aplicado|            N|          20240301|         20240425|           N|      20240301|     20240425|\n",
            "|   13587990|      0001|     58|               1|        N√£o aplicado|               02|          20110503|                   00|   N√£o aplicado|N√£o aplicado|             20110503|              4772500|       4781400,9602501|       AVENIDA|DOUTOR JOSE THOMA...|    57|        N√£o aplicado|       FAROLANDIA|49030270| SE|     3105|          79|    98320369|N√£o aplicado|N√£o aplicado|N√£o aplicado|N√£o aplicado|FALECONOSCO.JOSYC...|     N√£o aplicado|          N√£o aplicado|              NULL|                  NULL|                NULL|                 NULL|                        NULL|                NULL|                         NULL|                    NULL|                         NULL|                  NULL|                  NULL|13.587.990 JOSENI...|            2135|                          50|      30000,00|               01|        N√£o aplicado|            N|          20110503|         20241231|           N|      20110503|     20241231|\n",
            "|   53782995|      0001|     56|               1|       MCR DO BRASIL|               02|          20240202|                   00|   N√£o aplicado|         105|             20240202|              6204000|  6311900,6319400,6...|       AVENIDA|            PAULISTA|  1106|SALA  01         ...|       BELA VISTA|01310914| SP|     7107|          41|    98880068|        0000|    00000000|N√£o aplicado|N√£o aplicado|ABERTURA@CONTABIL...|     N√£o aplicado|          N√£o aplicado|               [2]|  [MARCELO DA CONCE...|       [***042907**]|                 [49]|                  [20240202]|                  []|                [***000000**]|                      []|                         [00]|                   [5]|  [S√≥cio-Administra...|GLOBAL TECNOLOGIA...|            2062|                          49|      12000,00|               01|        N√£o aplicado|            S|          20240202|         00000000|           N|      00000000|     00000000|\n",
            "|   40310289|      0001|     60|               1|        N√£o aplicado|               02|          20190606|                   00|   N√£o aplicado|N√£o aplicado|             20190606|              6911701|          N√£o aplicado|           RUA|BELARMINO DE MEND...|   107|           SALA  102|           CENTRO|85851100| PR|     7563|          45|    30290465|N√£o aplicado|N√£o aplicado|N√£o aplicado|N√£o aplicado|        N√£o aplicado|     N√£o aplicado|          N√£o aplicado|            [2, 2]|  [SANDRA ALVES GOG...|[***948169**, ***...|             [49, 49]|        [20190606, 20190606]|                  []|         [***000000**, ***...|                      []|                     [00, 00]|                [4, 5]|  [S√≥cio-Administra...|BITTENCOURT & GOG...|            2232|                          49|       2000,00|               01|        N√£o aplicado|            S|          20240101|         00000000|           N|      00000000|     00000000|\n",
            "|   35005578|      0001|     15|               1|LANCHONETE ESCORPIAO|               08|          20000519|                   01|   N√£o aplicado|N√£o aplicado|             19891003|              4723700|          N√£o aplicado|       AVENIDA|   SARGENTO HERMINIO|  1755|        N√£o aplicado|      SAO VICENTE|63700001| CE|     1383|N√£o aplicado|N√£o aplicado|N√£o aplicado|N√£o aplicado|N√£o aplicado|N√£o aplicado|        N√£o aplicado|     N√£o aplicado|          N√£o aplicado|              NULL|                  NULL|                NULL|                 NULL|                        NULL|                NULL|                         NULL|                    NULL|                         NULL|                  NULL|                  NULL|MARIA DE PAULA PO...|            2135|                          50|          0,00|               05|        N√£o aplicado| N√£o aplicado|      N√£o aplicado|     N√£o aplicado|N√£o aplicado|  N√£o aplicado| N√£o aplicado|\n",
            "+-----------+----------+-------+----------------+--------------------+-----------------+------------------+---------------------+---------------+------------+---------------------+---------------------+----------------------+--------------+--------------------+------+--------------------+-----------------+--------+---+---------+------------+------------+------------+------------+------------+------------+--------------------+-----------------+----------------------+------------------+----------------------+--------------------+---------------------+----------------------------+--------------------+-----------------------------+------------------------+-----------------------------+----------------------+----------------------+--------------------+----------------+----------------------------+--------------+-----------------+--------------------+-------------+------------------+-----------------+------------+--------------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "whKgm7PR4fxU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVrmslEm//0TYu2V63qBiR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}